{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. full connected neural network.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/adowaconan/Deep_learning_fMRI/blob/master/2_full_connected_neural_network.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "sSmmQnX4-AJD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# standard way of uploading data from your google drive to the colab working space"
      ]
    },
    {
      "metadata": {
        "id": "JJHhp3ADQyBg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "# 1. Authenticate and create the PyDrive client.\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "import numpy as np\n",
        "import zipfile\n",
        "data_id = {}\n",
        "data_id['3439'] = '1Y9NTSNs9sHoIa6DnGpPoq41yGWn4fkE6'#\n",
        "sub = '3439'\n",
        "file_id = data_id[sub]\n",
        "import os\n",
        "if not os.path.exists('/content/'+'sub_%s'%sub):\n",
        "    # import data from google drive to the working machine\n",
        "    zip_import = drive.CreateFile({'id':file_id})\n",
        "    zip_import.GetContentFile('sub_%s'%sub)\n",
        "    # unzip the file\n",
        "    zip_ref = zipfile.ZipFile('sub_%s'%sub,'r')\n",
        "    zip_ref.extractall()\n",
        "    zip_ref.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8NAcFdmL-Fvz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# instand python libraries using pip-install"
      ]
    },
    {
      "metadata": {
        "id": "2nvnAGMLRDLv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        },
        "outputId": "5bb6257e-40a0-4140-9277-3eaa4406a190"
      },
      "cell_type": "code",
      "source": [
        "!pip install tqdm\n",
        "!apt-get install swig\n",
        "!pip install -U pymvpa2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tqdm\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/ca/6524dfba7a0e850d3fda223693779035ddc8bf5c242acd9ee4eb9e52711a/tqdm-4.23.3-py2.py3-none-any.whl (42kB)\n",
            "\u001b[K    100% |████████████████████████████████| 51kB 3.6MB/s \n",
            "\u001b[?25hInstalling collected packages: tqdm\n",
            "Successfully installed tqdm-4.23.3\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  swig3.0\n",
            "Suggested packages:\n",
            "  swig-doc swig-examples swig3.0-examples swig3.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  swig swig3.0\n",
            "0 upgraded, 2 newly installed, 0 to remove and 0 not upgraded.\n",
            "Need to get 1,080 kB of archives.\n",
            "After this operation, 5,657 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu artful/universe amd64 swig3.0 amd64 3.0.10-1.2 [1,074 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu artful/universe amd64 swig amd64 3.0.10-1.2 [6,384 B]\n",
            "Fetched 1,080 kB in 1s (796 kB/s)\n",
            "Selecting previously unselected package swig3.0.\n",
            "(Reading database ... 18298 files and directories currently installed.)\n",
            "Preparing to unpack .../swig3.0_3.0.10-1.2_amd64.deb ...\n",
            "Unpacking swig3.0 (3.0.10-1.2) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../swig_3.0.10-1.2_amd64.deb ...\n",
            "Unpacking swig (3.0.10-1.2) ...\n",
            "Setting up swig3.0 (3.0.10-1.2) ...\n",
            "Setting up swig (3.0.10-1.2) ...\n",
            "Collecting pymvpa2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/66/da/edcd98d078fae8c017d2cd8434a827b50b7f59c1a35c2a42dfa934d0e974/pymvpa2-2.6.4.tar.gz (8.1MB)\n",
            "\u001b[K    100% |████████████████████████████████| 8.1MB 2.7MB/s \n",
            "\u001b[?25hRequirement not upgraded as not directly required: scipy in /usr/local/lib/python2.7/dist-packages (from pymvpa2) (0.19.1)\n",
            "Collecting nibabel (from pymvpa2)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/de/1d96fd0b118c9047bf35f02090db8ef8fd3927dfce635f09a6f7d5b572e6/nibabel-2.2.1.zip (4.2MB)\n",
            "\u001b[K    100% |████████████████████████████████| 4.2MB 7.2MB/s \n",
            "\u001b[?25hRequirement not upgraded as not directly required: numpy>=1.8.2 in /usr/local/lib/python2.7/dist-packages (from scipy->pymvpa2) (1.14.3)\n",
            "Building wheels for collected packages: pymvpa2, nibabel\n",
            "  Running setup.py bdist_wheel for pymvpa2 ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/c1/fe/dc/e43d539670974a0adb14a6f89c30ef710d273df10c82107512\n",
            "  Running setup.py bdist_wheel for nibabel ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \b|\b \b/\b \bdone\n",
            "\u001b[?25h  Stored in directory: /content/.cache/pip/wheels/46/50/8d/bcb0b8f7c030da5bac1752fbe9cc375cbf5725fa93ba79ad84\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Successfully built pymvpa2 nibabel\n",
            "Installing collected packages: nibabel, pymvpa2\n",
            "Successfully installed nibabel-2.2.1 pymvpa2-2.6.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "EYhfqkLY-Lnb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# as you see, keras in colab uses tensorflow as default backend"
      ]
    },
    {
      "metadata": {
        "id": "Ebx-Hig7RPi8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0743b8e4-1b31-436a-8458-6e97b56c136e"
      },
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "from collections import Counter\n",
        "from mvpa2.mappers.fx import mean_group_sample\n",
        "from mvpa2.generators.partition import NFoldPartitioner\n",
        "from mvpa2.base.node import ChainNode\n",
        "from mvpa2.generators.resampling import Balancer\n",
        "from mvpa2.generators.base import Sifter\n",
        "\n",
        "from keras.layers import Conv3D,Dense,Dropout,BatchNormalization\n",
        "from keras.layers import Input, AveragePooling3D\n",
        "from keras.layers import Flatten,Dense\n",
        "from keras.models import Model\n",
        "import keras\n",
        "from keras.callbacks import ModelCheckpoint,TensorBoard\n",
        "from sklearn import metrics\n",
        "import pandas as pd\n",
        "import os\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "ocf5g4AURUwN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Example data - fMRI ROI dataset\n",
        "\n",
        "1. when the subjects are in the scanner, they read or think deeper when a word is presented\n",
        "2. regions of interest are extracted and vectorized\n"
      ]
    },
    {
      "metadata": {
        "id": "vSXtk-lo-SEg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# load the data and average the volumns, taking the condition of \"reenact\""
      ]
    },
    {
      "metadata": {
        "id": "w4G1LkVhRScr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "pr_ds = pickle.load(open('/content/3439/roi_1_bin.pkl','rb'))\n",
        "pr_ds = pr_ds.get_mapped(mean_group_sample(['chunks','trials'],order='occurrence'))\n",
        "# get the chosen condition\n",
        "pr_ds = pr_ds[pr_ds.sa.context == 'reenact']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1GhZEb6RRuVD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "outputId": "5c827769-2e5d-4a65-8882-a067009a1021"
      },
      "cell_type": "code",
      "source": [
        "print(pr_ds.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset: 144x2336@float32, <sa: categories,chunks,context,sample_indices,targets,time_coords,time_indices,trials,words>, <fa: voxel_indices>, <a: imgaffine,imghdr,imgtype,mapper,voxel_dim,voxel_e...\n",
            "stats: mean=0.00086342 std=0.549984 var=0.302482 min=-2.8908 max=2.82391\n",
            "\n",
            "Counts of targets in each chunk:\n",
            "  chunks\\targets animal tool\n",
            "                   ---   ---\n",
            "        1          18    18\n",
            "        3          18    18\n",
            "        5          18    18\n",
            "        7          18    18\n",
            "\n",
            "Summary for targets across chunks\n",
            "  targets mean std min max #chunks\n",
            "  animal   18   0   18  18    4\n",
            "   tool    18   0   18  18    4\n",
            "\n",
            "Summary for chunks across targets\n",
            "  chunks mean std min max #targets\n",
            "    1     18   0   18  18     2\n",
            "    3     18   0   18  18     2\n",
            "    5     18   0   18  18     2\n",
            "    7     18   0   18  18     2\n",
            "Sequence statistics for 144 entries from set ['animal', 'tool']\n",
            "Counter-balance table for orders up to 2:\n",
            "Targets/Order O1     |  O2     |\n",
            "   animal:    36 35  |  32 38  |\n",
            "    tool:     35 37  |  39 33  |\n",
            "Correlations: min=-0.19 max=0.17 mean=-0.007 sum(abs)=8.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "yAOHE7E3SQDe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Input,Dense,Activation\n",
        "from keras.models import Sequential,Model\n",
        "from keras import optimizers,losses,metrics"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VFzx2HKJ-pWX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# a toy model of using only fully connected layers"
      ]
    },
    {
      "metadata": {
        "id": "5yIsrHwSSvGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "outputId": "1b88ebc9-2075-420b-f6a3-8d5f9b9a13aa"
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(32, input_shape=(2336,)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dense(2))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_7 (Dense)              (None, 32)                74784     \n",
            "_________________________________________________________________\n",
            "activation_7 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2)                 66        \n",
            "_________________________________________________________________\n",
            "activation_8 (Activation)    (None, 2)                 0         \n",
            "=================================================================\n",
            "Total params: 74,850\n",
            "Trainable params: 74,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CZ-tNC6l-tjM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# add an optimizer and a loss function before your training"
      ]
    },
    {
      "metadata": {
        "id": "qWx1oxRIS16_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizers.Adam(),loss=losses.binary_crossentropy,metrics=['categorical_accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6AsqR3D-yOG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# tensorflow takes tensor matrices or numpy array, thus, we need to convert the data to numpy  array with float32 or float64. The float number conversion is tricky and we will talk about it later"
      ]
    },
    {
      "metadata": {
        "id": "EGgBnQUOUKqI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2726
        },
        "outputId": "fd586bb1-7d40-4891-8d8f-a2ef6e091d03"
      },
      "cell_type": "code",
      "source": [
        "data = pr_ds.samples\n",
        "label_map = {'animal':[0,1],'tool':[1,0]}\n",
        "labels = np.array([label_map[item] for item in pr_ds.targets])\n",
        "data,labels"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.28787753,  0.52017474,  0.23097952, ...,  0.54967576,\n",
              "          0.42195216,  0.09478402],\n",
              "        [ 0.0090575 , -0.20558704, -0.10110297, ..., -0.24365346,\n",
              "         -0.18717152, -0.2724901 ],\n",
              "        [ 0.77175385,  0.33383298,  0.8632676 , ...,  0.59843194,\n",
              "         -0.33976305, -0.21052049],\n",
              "        ...,\n",
              "        [ 0.6065182 , -0.3108139 , -0.240719  , ...,  0.38944736,\n",
              "          0.51658106,  0.04471493],\n",
              "        [-0.60012674, -0.43406656, -0.2635417 , ..., -0.40048814,\n",
              "         -0.37045285,  0.09566599],\n",
              "        [-0.27681738, -0.69222397, -0.56372875, ...,  0.25518915,\n",
              "         -0.17328219, -0.33957395]], dtype=float32), array([[0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [1, 0],\n",
              "        [0, 1],\n",
              "        [0, 1],\n",
              "        [0, 1]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "metadata": {
        "id": "zTpxE9-k_Aww",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# call \"fit\" function to fit the data. Here, we did not do a cross validation"
      ]
    },
    {
      "metadata": {
        "id": "cPtBRruGU2h7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "ba42b9d7-a05e-4ca8-9819-4997d1ddcf14"
      },
      "cell_type": "code",
      "source": [
        "model.fit(data,labels,batch_size=32,epochs=5,validation_split=0.2,)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 115 samples, validate on 29 samples\n",
            "Epoch 1/5\n",
            "115/115 [==============================] - 0s 2ms/step - loss: 0.6768 - categorical_accuracy: 0.5826 - val_loss: 0.5944 - val_categorical_accuracy: 0.7241\n",
            "Epoch 2/5\n",
            "115/115 [==============================] - 0s 216us/step - loss: 0.2489 - categorical_accuracy: 0.8870 - val_loss: 0.5429 - val_categorical_accuracy: 0.7241\n",
            "Epoch 3/5\n",
            "115/115 [==============================] - 0s 181us/step - loss: 0.1304 - categorical_accuracy: 0.9652 - val_loss: 0.5472 - val_categorical_accuracy: 0.7586\n",
            "Epoch 4/5\n",
            "115/115 [==============================] - 0s 176us/step - loss: 0.0707 - categorical_accuracy: 1.0000 - val_loss: 0.5554 - val_categorical_accuracy: 0.7931\n",
            "Epoch 5/5\n",
            "115/115 [==============================] - 0s 188us/step - loss: 0.0442 - categorical_accuracy: 1.0000 - val_loss: 0.5650 - val_categorical_accuracy: 0.7931\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe394366990>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "metadata": {
        "id": "LwohOOcQVDmC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}